{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMDgM80IuqHT/SSmiA/sTwc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chanaka3534/FYP_XGBOOST-Use-past-30-days-data-/blob/1.0/FYP_XGBOOST(Use_past_30_days_data).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "p3768oFz89aj"
      },
      "outputs": [],
      "source": [
        "# ðŸ“Œ 1) Imports\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ 2) Load your data\n",
        "df = pd.read_csv(\"FYP_DATA.csv\")"
      ],
      "metadata": {
        "id": "wWmwSWYi9T6s"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ 3) Clean numeric columns\n",
        "df['Resovior water level(m)'] = pd.to_numeric(df['Resovior water level(m)'], errors='coerce')\n",
        "df['Resovior discharge rate'] = pd.to_numeric(df['Resovior discharge rate'], errors='coerce')\n",
        "df['Water level(Kaliodai)'] = pd.to_numeric(df['Water level(Kaliodai)'], errors='coerce')\n",
        "\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "iyut_o3-9WPB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ 4) Sort by Date\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df = df.sort_values('Date')"
      ],
      "metadata": {
        "id": "MqK2igH79V_h"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ 5) Create 30 lag features for each column you want\n",
        "lag_days = 30\n",
        "\n",
        "for col in ['Catchment Rainfall', 'Downstream rainfall',\n",
        "            'Resovior water level(m)', 'Resovior discharge rate',\n",
        "            'Water level(Kaliodai)']:\n",
        "    for lag in range(1, lag_days + 1):\n",
        "        df[f'{col}(-{lag})'] = df[col].shift(lag)"
      ],
      "metadata": {
        "id": "JWOSdIIg9V9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ 6) Target: flood risk for today (or you can shift -1 for tomorrow)\n",
        "df['Flood risk target'] = df['Flood risk'].shift(-1)  # Predict tomorrow"
      ],
      "metadata": {
        "id": "V3ec6jfB9gIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ 7) Drop rows with any missing values due to shifting\n",
        "df_lagged = df.dropna()\n",
        "\n",
        "# ðŸ“Œ 8) Define features and target\n",
        "features = []\n",
        "for col in ['Catchment Rainfall', 'Downstream rainfall',\n",
        "            'Resovior water level(m)', 'Resovior discharge rate',\n",
        "            'Water level(Kaliodai)']:\n",
        "    for lag in range(1, lag_days + 1):\n",
        "        features.append(f'{col}(-{lag})')\n",
        "\n",
        "X = df_lagged[features]\n",
        "y = df_lagged['Flood risk target']\n",
        "\n",
        "# Encode target labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# ðŸ“Œ 9) Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Nk8FUKNu9oYp"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ 10) Train XGBoost\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', n_estimators=20)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "XrhoWv0p9pub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Œ 11) Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    labels=range(len(le.classes_)),\n",
        "    target_names=le.classes_\n",
        "))\n",
        "print(\"\\nConfusion Matrix:\\n\")\n",
        "print(confusion_matrix(y_test, y_pred, labels=range(len(le.classes_))))"
      ],
      "metadata": {
        "id": "KXbbl3PL9ryt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Your 30-day manual input (list of 30 rows)\n",
        "manual_data = [\n",
        "    [6.7, 0, 103.2, 1700, 1200],\n",
        "    [9.1, 0, 103.2, 1700, 1200],\n",
        "    [10, 10.5, 103.1, 1700, 900],\n",
        "    [9.5, 0, 103.1, 1500, 900],\n",
        "    [16.2, 0, 103, 1700, 800],\n",
        "    [13.6, 28.4, 102.9, 1600, 800],\n",
        "    [6.3, 16, 102.8, 1600, 800],\n",
        "    [13.6, 3.2, 102.8, 400, 1500],\n",
        "    [1.7, 0, 102.9, 500, 1500],\n",
        "    [1.3, 29.3, 103.1, 500, 1500],\n",
        "    [14.1, 0, 103.3, 300, 1500],\n",
        "    [0.5, 0, 103.5, 1100, 1500],\n",
        "    [2.5, 0, 103.5, 750, 1500],\n",
        "    [3.7, 0, 103.4, 750, 1500],\n",
        "    [13.5, 0, 103.4, 1050, 1200],\n",
        "    [4.7, 0, 103.8, 1150, 1200],\n",
        "    [4.9, 0, 103.9, 1600, 900],\n",
        "    [0.4, 0, 103.9, 1600, 900],\n",
        "    [2.1, 2, 103.9, 1800, 900],\n",
        "    [2.6, 0, 103.9, 1500, 700],\n",
        "    [1.1, 0, 103.9, 1600, 700],\n",
        "    [7, 5.3, 103.9, 1600, 1100],\n",
        "    [8.6, 0, 104.1, 1250, 2500],\n",
        "    [2.7, 0, 104.2, 1150, 2500],\n",
        "    [5.4, 0, 104.4, 1150, 2000],\n",
        "    [13.3, 0, 104.4, 1250, 2000],\n",
        "    [1.7, 0, 104.5, 1250, 2300],\n",
        "    [15.3, 0, 104.6, 1250, 2300],\n",
        "    [4, 0, 104.8, 900, 2300],\n",
        "    [15.1, 22, 105.1, 0, 2300],\n",
        "]\n",
        "\n",
        "# âœ… Convert rows to columns: separate lists\n",
        "import numpy as np\n",
        "\n",
        "manual_data_array = np.array(manual_data)\n",
        "\n",
        "# Now split columns:\n",
        "catchment_rainfall_30 = manual_data_array[:, 0].tolist()\n",
        "downstream_rainfall_30 = manual_data_array[:, 1].tolist()\n",
        "reservoir_level_30 = manual_data_array[:, 2].tolist()\n",
        "discharge_rate_30 = manual_data_array[:, 3].tolist()\n",
        "kaliodai_level_30 = manual_data_array[:, 4].tolist()\n",
        "\n",
        "# Combine all 5 in order:\n",
        "manual_input = (\n",
        "    catchment_rainfall_30\n",
        "    + downstream_rainfall_30\n",
        "    + reservoir_level_30\n",
        "    + discharge_rate_30\n",
        "    + kaliodai_level_30\n",
        ")\n",
        "\n",
        "print(f\"Manual input length: {len(manual_input)}\")\n",
        "\n",
        "# âœ… Now predict:\n",
        "manual_pred = model.predict([manual_input])\n",
        "print(\"Predicted Flood Risk for tomorrow:\", le.inverse_transform(manual_pred)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbjCEGWa9wGz",
        "outputId": "8a2be62b-46b5-4aae-9ce6-f3544ebe3e9a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual input length: 150\n",
            "Predicted Flood Risk for tomorrow: NO\n"
          ]
        }
      ]
    }
  ]
}